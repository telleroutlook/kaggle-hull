"""
ç‰¹å¾å·¥ç¨‹å¢å¼ºæ¼”ç¤ºè„šæœ¬
å±•ç¤ºæ–°åŠŸèƒ½å¦‚ä½•æå‡æ¨¡å‹é¢„æµ‹èƒ½åŠ›
"""

import numpy as np
import pandas as pd
import sys
import os
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ workingç›®å½•åˆ°è·¯å¾„
working_dir = os.path.dirname(os.path.dirname(__file__))
if working_dir not in sys.path:
    sys.path.insert(0, working_dir)

from lib.features import FeaturePipeline
from lib.data import load_train_data, load_test_data
from lib.env import detect_run_environment, get_data_paths


def create_enhanced_demo_data():
    """åˆ›å»ºæ¼”ç¤ºç”¨çš„å¢å¼ºæ•°æ®é›†"""
    np.random.seed(42)
    n_samples = 200
    
    # åˆ›å»ºåŸºç¡€å¸‚åœºæ•°æ®
    data = {
        'date_id': range(n_samples),
        'M1': np.random.randn(n_samples) * 0.02,
        'M2': np.random.randn(n_samples) * 0.02,
        'M3': np.random.randn(n_samples) * 0.02,
        'M4': np.random.randn(n_samples) * 0.02,
        'M5': np.random.randn(n_samples) * 0.02,
        'P1': 100 + np.cumsum(np.random.randn(n_samples) * 0.5),  # ä»·æ ¼åºåˆ—
        'P2': 100 + np.cumsum(np.random.randn(n_samples) * 0.5),
        'P3': 100 + np.cumsum(np.random.randn(n_samples) * 0.5),
        'V1': np.random.exponential(0.02, n_samples),  # æ³¢åŠ¨ç‡
        'V2': np.random.exponential(0.02, n_samples),
        'E1': np.random.randn(n_samples) * 0.01,
        'E2': np.random.randn(n_samples) * 0.01,
        'E3': np.random.randn(n_samples) * 0.01,
        'S1': np.random.randn(n_samples) * 0.5,
        'S2': np.random.randn(n_samples) * 0.5,
        'I1': np.random.uniform(0.01, 0.05, n_samples),  # åˆ©ç‡
        'MOM1': np.random.randn(n_samples) * 0.01,
        'MOM2': np.random.randn(n_samples) * 0.01,
        'lagged_forward_returns': np.random.randn(n_samples) * 0.01,
        'lagged_risk_free_rate': np.random.uniform(0.01, 0.05, n_samples),
        'lagged_market_forward_excess_returns': np.random.randn(n_samples) * 0.01,
        'forward_returns': np.random.randn(n_samples) * 0.01,
        'risk_free_rate': np.random.uniform(0.01, 0.05, n_samples),
        'market_forward_excess_returns': np.random.randn(n_samples) * 0.01,
    }
    
    return pd.DataFrame(data)


def demonstrate_enhanced_features():
    """æ¼”ç¤ºå¢å¼ºç‰¹å¾å·¥ç¨‹åŠŸèƒ½"""
    
    print("ğŸš€ ç‰¹å¾å·¥ç¨‹å¢å¼ºæ¼”ç¤º")
    print("=" * 50)
    
    # 1. åˆ›å»ºæ¼”ç¤ºæ•°æ®
    print("\nğŸ“Š 1. åˆ›å»ºæ¼”ç¤ºæ•°æ®")
    demo_data = create_enhanced_demo_data()
    print(f"   æ•°æ®å½¢çŠ¶: {demo_data.shape}")
    print(f"   ç‰¹å¾åˆ—: {len([col for col in demo_data.columns if not col.startswith(('date_id', 'forward', 'risk_free', 'market_forward', 'lagged_'))])}")
    
    # 2. åŸºç¡€ç‰¹å¾å·¥ç¨‹
    print("\nğŸ”§ 2. åŸºç¡€ç‰¹å¾å·¥ç¨‹")
    basic_pipeline = FeaturePipeline(
        extra_group_stats=False,
        enable_data_quality=False,
        enable_feature_stability=False,
        outlier_detection=False
    )
    
    basic_features = basic_pipeline.fit_transform(demo_data)
    print(f"   åŸºç¡€ç‰¹å¾æ•°é‡: {basic_features.shape[1]}")
    
    # 3. å¢å¼ºç‰¹å¾å·¥ç¨‹
    print("\nâš¡ 3. å¢å¼ºç‰¹å¾å·¥ç¨‹")
    enhanced_pipeline = FeaturePipeline(
        extra_group_stats=True,
        enable_data_quality=True,
        enable_feature_stability=True,
        outlier_detection=True,
        missing_value_strategy="median",
        clip_quantile=0.01
    )
    
    enhanced_features = enhanced_pipeline.fit_transform(demo_data)
    print(f"   å¢å¼ºç‰¹å¾æ•°é‡: {enhanced_features.shape[1]}")
    print(f"   ç‰¹å¾å¢åŠ : {enhanced_features.shape[1] - basic_features.shape[1]} (+{((enhanced_features.shape[1] - basic_features.shape[1]) / basic_features.shape[1] * 100):.1f}%)")
    
    # 4. å±•ç¤ºé«˜çº§æŠ€æœ¯æŒ‡æ ‡
    print("\nğŸ“ˆ 4. é«˜çº§æŠ€æœ¯æŒ‡æ ‡")
    tech_indicators = [
        'rsi_14', 'williams_r_14', 'stoch_k_14', 'stoch_d_14', 
        'adx_value', 'adx_plus_di', 'adx_minus_di', 'macd_12_26',
        'macd_signal_12_26', 'macd_hist_12_26', 'ma_cross_5_20', 
        'bollinger_width_20', 'vol_ratio_10'
    ]
    
    available_indicators = [ind for ind in tech_indicators if ind in enhanced_features.columns]
    print(f"   ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡: {len(available_indicators)}")
    for indicator in available_indicators[:5]:
        values = enhanced_features[indicator]
        print(f"   - {indicator}: å‡å€¼={values.mean():.4f}, æ ‡å‡†å·®={values.std():.4f}")
    
    # 5. å±•ç¤ºåˆ†å±‚ç»Ÿè®¡ç‰¹å¾
    print("\nğŸ“Š 5. åˆ†å±‚ç»Ÿè®¡ç‰¹å¾")
    tiered_features = [col for col in enhanced_features.columns if any(suffix in col for suffix in ['_mean_low_vol', '_std_high_vol', '_mean_strong_trend'])]
    print(f"   ç”Ÿæˆåˆ†å±‚ç»Ÿè®¡ç‰¹å¾: {len(tiered_features)}")
    
    # 6. å±•ç¤ºå®è§‚å› å­äº¤äº’
    print("\nğŸŒ 6. å®è§‚å› å­äº¤äº’")
    macro_features = [col for col in enhanced_features.columns if any(keyword in col for keyword in ['rate_adjusted', 'vol_weighted', 'economic_', 'sentiment_'])]
    print(f"   ç”Ÿæˆå®è§‚äº¤äº’ç‰¹å¾: {len(macro_features)}")
    
    # 7. æ•°æ®è´¨é‡åˆ†æ
    print("\nğŸ” 7. æ•°æ®è´¨é‡åˆ†æ")
    quality_report = enhanced_pipeline.get_data_quality_report()
    quality_metrics = quality_report['quality_metrics']
    stability_scores = quality_report['stability_scores']
    
    print(f"   åˆ†æç‰¹å¾æ•°é‡: {len(quality_metrics)}")
    print(f"   ç¨³å®šæ€§åˆ†æç‰¹å¾: {len(stability_scores)}")
    
    # å±•ç¤ºéƒ¨åˆ†è´¨é‡æŒ‡æ ‡
    sample_features = list(quality_metrics.keys())[:3]
    for feature in sample_features:
        metrics = quality_metrics[feature]
        print(f"   - {feature}: ç¼ºå¤±ç‡={metrics['missing_rate']:.3f}, ååº¦={metrics['skewness']:.3f}")
    
    # 8. ç‰¹å¾é€‰æ‹©
    print("\nğŸ¯ 8. ç‰¹å¾é€‰æ‹©")
    stable_features = enhanced_pipeline.get_stable_features(threshold=0.1)
    risky_features = enhanced_pipeline.get_risky_features(threshold=0.1)
    
    print(f"   ç¨³å®šç‰¹å¾ (é˜ˆå€¼â‰¥0.1): {len(stable_features)}")
    print(f"   é£é™©ç‰¹å¾ (é˜ˆå€¼<0.1): {len(risky_features)}")
    
    # 9. å¼‚å¸¸å€¼å¤„ç†
    print("\nğŸš¨ 9. å¼‚å¸¸å€¼å¤„ç†")
    outlier_bounds = enhanced_pipeline.outlier_bounds
    print(f"   è®¾ç½®å¼‚å¸¸å€¼è¾¹ç•Œ: {len(outlier_bounds)} ä¸ªç‰¹å¾")
    
    # 10. æ€»ç»“
    print("\nâœ… 10. æ€»ç»“")
    print(f"   åŸºç¡€ç‰¹å¾ â†’ å¢å¼ºç‰¹å¾: {basic_features.shape[1]} â†’ {enhanced_features.shape[1]}")
    print(f"   ç‰¹å¾å¢é•¿: +{enhanced_features.shape[1] - basic_features.shape[1]} ä¸ªç‰¹å¾")
    print(f"   æŠ€æœ¯æŒ‡æ ‡: {len(available_indicators)} ä¸ª")
    print(f"   åˆ†å±‚ç»Ÿè®¡: {len(tiered_features)} ä¸ª")
    print(f"   å®è§‚äº¤äº’: {len(macro_features)} ä¸ª")
    print(f"   æ•°æ®è´¨é‡ç‰¹å¾: âœ…")
    print(f"   å¼‚å¸¸å€¼å¤„ç†: âœ…")
    print(f"   ç‰¹å¾ç¨³å®šæ€§åˆ†æ: âœ…")
    
    print("\nğŸ‰ ç‰¹å¾å·¥ç¨‹å¢å¼ºæ¼”ç¤ºå®Œæˆ!")
    return enhanced_pipeline, enhanced_features


if __name__ == "__main__":
    try:
        pipeline, features = demonstrate_enhanced_features()
        print(f"\nğŸ“ æ¼”ç¤ºæ•°æ®å¯ä»pipelineå¯¹è±¡è·å–")
        print(f"   ç®¡é“ç±»å‹: {type(pipeline)}")
        print(f"   ç‰¹å¾å½¢çŠ¶: {features.shape}")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()