#!/usr/bin/env python3
"""
Hull Tactical - è¶…å‚æ•°è°ƒä¼˜æ¼”ç¤ºå’Œæµ‹è¯•è„šæœ¬
å®Œæ•´çš„è°ƒä¼˜æµç¨‹æ¼”ç¤ºï¼ŒåŒ…æ‹¬æ•°æ®åˆ†æã€æ¨¡å‹è°ƒä¼˜ã€ç»“æœåˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ
"""

import os
import sys
import time
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, Any
import json
import warnings

warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

def run_quick_tuning_demo():
    """è¿è¡Œå¿«é€Ÿè°ƒä¼˜æ¼”ç¤º"""
    print("ğŸš€ Hull Tactical - è¶…å‚æ•°è°ƒä¼˜ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)
    
    # 1. å¯¼å…¥æ‰€éœ€æ¨¡å—
    try:
        from hyperparameter_tuning import run_tuning_experiments, TuningConfig
        from tuning_results import TuningResultAnalyzer
        from lib.config import get_config
        from lib.data import load_train_data
        from lib.features import FeaturePipeline
        print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–: optuna, matplotlib, seaborn, plotly")
        return False
    
    # 2. æ£€æŸ¥æ•°æ®
    data_path = "input/hull-tactical-market-prediction"
    train_file = Path(data_path) / "train.csv"
    
    if not train_file.exists():
        print(f"âš ï¸ è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {train_file}")
        print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å·²æ­£ç¡®æ”¾ç½®")
        return False
    
    print(f"ğŸ“ æ‰¾åˆ°è®­ç»ƒæ•°æ®: {train_file}")
    
    # 3. åˆ›å»ºå¿«é€Ÿè°ƒä¼˜é…ç½®
    print("\nâš™ï¸ é…ç½®è°ƒä¼˜å‚æ•°...")
    config = TuningConfig(
        model_types=["lightgbm", "xgboost"],  # å‡å°‘æ¨¡å‹æ•°é‡ä»¥åŠ å¿«æ¼”ç¤º
        n_trials=20,  # å‡å°‘è¯•éªŒæ¬¡æ•°
        cv_folds=3,
        validation_strategy="time_series",
        search_strategy="optuna",
        timeout_seconds=600,  # 10åˆ†é’Ÿè¶…æ—¶
        primary_metric="mse",
        secondary_metrics=["mae"],
        output_dir="demo_tuning_results"
    )
    
    print(f"ğŸ“Š è°ƒä¼˜é…ç½®:")
    print(f"   æ¨¡å‹: {config.model_types}")
    print(f"   è¯•éªŒæ¬¡æ•°: {config.n_trials}")
    print(f"   éªŒè¯æŠ˜æ•°: {config.cv_folds}")
    print(f"   ä¸»è¦æŒ‡æ ‡: {config.primary_metric}")
    
    # 4. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
    print("\nğŸ“¥ åŠ è½½å’Œé¢„å¤„ç†æ•°æ®...")
    try:
        train_data = pd.read_csv(train_file)
        print(f"   åŸå§‹æ•°æ®: {train_data.shape}")
        
        # åŸºç¡€ç‰¹å¾å·¥ç¨‹
        pipeline = FeaturePipeline(stateful=True)
        X = pipeline.fit_transform(train_data)
        y = train_data["forward_returns"].fillna(train_data["forward_returns"].median())
        
        print(f"   ç‰¹å¾å·¥ç¨‹å: {X.shape}")
        print(f"   ç›®æ ‡å˜é‡ç»Ÿè®¡: å‡å€¼={y.mean():.4f}, æ ‡å‡†å·®={y.std():.4f}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 5. è¿è¡Œè°ƒä¼˜
    print("\nğŸ”§ å¼€å§‹è¶…å‚æ•°è°ƒä¼˜...")
    start_time = time.time()
    
    try:
        from hyperparameter_tuning import HyperparameterTuner
        
        tuner = HyperparameterTuner(config)
        results = tuner.tune_all_models(X, y)
        
        tuning_time = time.time() - start_time
        print(f"âœ… è°ƒä¼˜å®Œæˆ! è€—æ—¶: {tuning_time:.1f}ç§’")
        
    except Exception as e:
        print(f"âŒ è°ƒä¼˜å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 6. åˆ†æç»“æœ
    print("\nğŸ“Š åˆ†æè°ƒä¼˜ç»“æœ...")
    try:
        analyzer = TuningResultAnalyzer("demo_tuning_results")
        analyzer.load_results()
        analyzer.analyze_model_performance()
        summary = analyzer.generate_performance_summary()
        
        print(f"   å®éªŒæ•°é‡: {summary['total_experiments']}")
        print(f"   æ¨¡å‹ç±»å‹: {summary['unique_models']}")
        
        if summary['model_rankings']:
            best_model = min(summary['model_rankings'].keys(), 
                           key=lambda x: summary['model_rankings'][x])
            best_score = summary['model_rankings'][best_model]
            print(f"   ğŸ† æœ€ä½³æ¨¡å‹: {best_model} (MSE: {best_score:.4f})")
        
    except Exception as e:
        print(f"âš ï¸ ç»“æœåˆ†æå¤±è´¥: {e}")
    
    # 7. ä¿å­˜è°ƒä¼˜ç»“æœåˆ°é…ç½®
    print("\nğŸ’¾ ä¿å­˜è°ƒä¼˜ç»“æœåˆ°é…ç½®...")
    try:
        config_manager = get_config()
        
        for model_type, result in results.items():
            config_manager.save_tuned_parameters(
                model_type=model_type,
                params=result.best_params,
                best_score=result.best_score
            )
            print(f"   âœ… {model_type} å‚æ•°å·²ä¿å­˜")
        
        print("   ğŸ’¡ å»ºè®®é‡æ–°è¿è¡Œä¸»æ¨¡å‹ä»¥ä½¿ç”¨ä¼˜åŒ–å‚æ•°")
        
    except Exception as e:
        print(f"âš ï¸ é…ç½®ä¿å­˜å¤±è´¥: {e}")
    
    # 8. ç”ŸæˆæŠ¥å‘Š
    print("\nğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    try:
        chart1 = analyzer.create_performance_comparison_chart()
        chart2 = analyzer.create_model_ranking_chart()
        html_report = analyzer.generate_html_report()
        
        print(f"   ğŸ“Š æ€§èƒ½å›¾è¡¨: {chart1}")
        print(f"   ğŸ† æ’åå›¾è¡¨: {chart2}")
        print(f"   ğŸ“„ HTMLæŠ¥å‘Š: {html_report}")
        
    except Exception as e:
        print(f"âš ï¸ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
    
    # 9. æ¼”ç¤ºç»“è®º
    print("\n" + "=" * 60)
    print("ğŸ‰ è°ƒä¼˜æ¼”ç¤ºå®Œæˆ!")
    print("=" * 60)
    
    print(f"\nğŸ“‹ æ€»ç»“:")
    print(f"   â±ï¸  æ€»è€—æ—¶: {tuning_time:.1f}ç§’")
    print(f"   ğŸ§ª è¯•éªŒæ€»æ•°: {sum(r.n_trials for r in results.values())}")
    print(f"   ğŸ† æœ€ä½³æ¨¡å‹: {best_model if 'best_model' in locals() else 'N/A'}")
    
    if results:
        print(f"\nğŸ“ˆ å„æ¨¡å‹æ€§èƒ½:")
        for model_type, result in results.items():
            improvement = ""
            print(f"   {model_type}: MSE={result.best_score:.4f}, è¯•éªŒæ•°={result.n_trials}")
    
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"   è°ƒä¼˜ç»“æœ: demo_tuning_results/")
    print(f"   HTMLæŠ¥å‘Š: {html_report if 'html_report' in locals() else 'ç”Ÿæˆå¤±è´¥'}")
    
    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
    print(f"   1. æŸ¥çœ‹HTMLæŠ¥å‘Šäº†è§£è¯¦ç»†åˆ†æ")
    print(f"   2. è¿è¡Œ python main.py æµ‹è¯•ä¼˜åŒ–åçš„æ¨¡å‹")
    print(f"   3. æ ¹æ®éœ€è¦è°ƒæ•´è°ƒä¼˜å‚æ•°è¿›è¡Œæ·±åº¦ä¼˜åŒ–")
    
    return True


def test_optimized_models():
    """æµ‹è¯•ä¼˜åŒ–åçš„æ¨¡å‹æ€§èƒ½"""
    print("\nğŸ§ª æµ‹è¯•ä¼˜åŒ–åçš„æ¨¡å‹æ€§èƒ½...")
    
    try:
        from lib.model_registry import get_model_params
        from lib.config import get_config
        
        config = get_config()
        
        print("ğŸ“Š å½“å‰æ¨¡å‹å‚æ•°é…ç½®:")
        for model_type in ["lightgbm", "xgboost", "catboost"]:
            params = get_model_params(model_type)
            is_tuned = config.is_tuning_enabled() and config.get_tuned_parameters(model_type)
            status = "ğŸ¯ å·²è°ƒä¼˜" if is_tuned else "ğŸ“‹ é»˜è®¤"
            print(f"   {model_type}: {status} ({len(params)}ä¸ªå‚æ•°)")
        
        print("\nâœ… é…ç½®ç³»ç»Ÿå·¥ä½œæ­£å¸¸!")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False


def create_usage_examples():
    """åˆ›å»ºä½¿ç”¨ç¤ºä¾‹"""
    print("\nğŸ“š åˆ›å»ºä½¿ç”¨ç¤ºä¾‹...")
    
    examples_dir = Path("tuning_examples")
    examples_dir.mkdir(exist_ok=True)
    
    # 1. åŸºç¡€è°ƒä¼˜ç¤ºä¾‹
    basic_example = '''#!/usr/bin/env python3
"""
åŸºç¡€è¶…å‚æ•°è°ƒä¼˜ç¤ºä¾‹
"""

from hyperparameter_tuning import run_tuning_experiments

# è¿è¡ŒåŸºç¡€è°ƒä¼˜
tuner, results = run_tuning_experiments(
    data_path="input/hull-tactical-market-prediction",
    output_dir="my_tuning_results"
)

print(f"æœ€ä½³æ¨¡å‹: {tuner.get_ranking()[0][0]}")
'''
    
    with open(examples_dir / "basic_tuning.py", 'w') as f:
        f.write(basic_example)
    
    # 2. è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹
    custom_example = '''#!/usr/bin/env python3
"""
è‡ªå®šä¹‰é…ç½®è°ƒä¼˜ç¤ºä¾‹
"""

from hyperparameter_tuning import TuningConfig, HyperparameterTuner
from lib.data import load_train_data
from lib.features import FeaturePipeline

# è‡ªå®šä¹‰é…ç½®
config = TuningConfig(
    model_types=["lightgbm", "xgboost", "catboost"],
    n_trials=100,
    cv_folds=5,
    search_strategy="optuna",
    validation_strategy="time_series",
    primary_metric="mse",
    secondary_metrics=["mae", "r2"],
    timeout_seconds=3600
)

# åŠ è½½æ•°æ®
train_data = load_train_data("input/hull-tactical-market-prediction")
pipeline = FeaturePipeline(stateful=True)
X = pipeline.fit_transform(train_data)
y = train_data["forward_returns"].fillna(train_data["forward_returns"].median())

# è¿è¡Œè°ƒä¼˜
tuner = HyperparameterTuner(config)
results = tuner.tune_all_models(X, y)

# ä¿å­˜ç»“æœ
tuner.save_results("my_custom_tuning.json")
'''
    
    with open(examples_dir / "custom_tuning.py", 'w') as f:
        f.write(custom_example)
    
    # 3. ç»“æœåˆ†æç¤ºä¾‹
    analysis_example = '''#!/usr/bin/env python3
"""
è°ƒä¼˜ç»“æœåˆ†æç¤ºä¾‹
"""

from tuning_results import TuningResultAnalyzer

# åˆ›å»ºåˆ†æå™¨
analyzer = TuningResultAnalyzer("tuning_results")

# åŠ è½½å’Œåˆ†æç»“æœ
analyzer.load_results()
analyzer.analyze_model_performance()
summary = analyzer.generate_performance_summary()

# ç”ŸæˆæŠ¥å‘Š
chart1 = analyzer.create_performance_comparison_chart()
chart2 = analyzer.create_model_ranking_chart()
html_report = analyzer.generate_html_report()

print(f"æŠ¥å‘Šç”Ÿæˆå®Œæˆ: {html_report}")
'''
    
    with open(examples_dir / "analyze_results.py", 'w') as f:
        f.write(analysis_example)
    
    print(f"âœ… ç¤ºä¾‹æ–‡ä»¶å·²åˆ›å»ºåœ¨: {examples_dir}/")
    print("   basic_tuning.py - åŸºç¡€è°ƒä¼˜")
    print("   custom_tuning.py - è‡ªå®šä¹‰é…ç½®")
    print("   analyze_results.py - ç»“æœåˆ†æ")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Hull Tactical è°ƒä¼˜æ¼”ç¤º")
    parser.add_argument("--quick", action="store_true", help="å¿«é€Ÿæ¼”ç¤º")
    parser.add_argument("--test", action="store_true", help="æµ‹è¯•é…ç½®")
    parser.add_argument("--examples", action="store_true", help="åˆ›å»ºç¤ºä¾‹")
    
    args = parser.parse_args()
    
    if not any([args.quick, args.test, args.examples]):
        args.quick = True  # é»˜è®¤è¿è¡Œå¿«é€Ÿæ¼”ç¤º
    
    success = True
    
    if args.test:
        success &= test_optimized_models()
    
    if args.examples:
        create_usage_examples()
    
    if args.quick:
        success &= run_quick_tuning_demo()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æ“ä½œå®Œæˆ!")
    else:
        print("\nâŒ æŸäº›æ“ä½œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    
    return 0 if success else 1


if __name__ == "__main__":
    exit(main())