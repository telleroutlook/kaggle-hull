#!/usr/bin/env python3
"""
é«˜çº§é›†æˆç­–ç•¥æ€§èƒ½åŸºå‡†æµ‹è¯•
æ¯”è¾ƒä¸åŒé›†æˆæ–¹æ³•çš„æ€§èƒ½è¡¨ç°
"""

import sys
import os
import time
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Tuple
import warnings

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

# æŠ‘åˆ¶è­¦å‘Š
warnings.filterwarnings('ignore')

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
try:
    from lib.models import (
        HullModel, 
        DynamicWeightedEnsemble,
        StackingEnsemble, 
        RiskAwareEnsemble,
        AveragingEnsemble,
        create_baseline_model,
        create_submission
    )
    from lib.features import FeaturePipeline
    from lib.evaluation import backtest_strategy
    from lib.utils import PerformanceTracker
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸­è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


def create_synthetic_data(n_samples: int = 1000, n_features: int = 20) -> Tuple[pd.DataFrame, pd.Series, pd.Series]:
    """åˆ›å»ºåˆæˆæ•°æ®ç”¨äºåŸºå‡†æµ‹è¯•"""
    
    np.random.seed(42)
    
    # åˆ›å»ºç‰¹å¾
    features = {}
    for i in range(n_features):
        features[f'feature_{i}'] = np.random.randn(n_samples)
    
    # åˆ›å»ºç›®æ ‡å˜é‡ï¼ˆåŸºäºç‰¹å¾çš„çº¿æ€§ç»„åˆ + å™ªå£°ï¼‰
    weights = np.random.randn(n_features)
    signal = sum(features[f'feature_{i}'] * weights[i] for i in range(n_features)) / n_features
    target = signal + 0.1 * np.random.randn(n_samples)
    
    # åˆ›å»ºå¸‚åœºæ”¶ç›Šç‡
    market_returns = 0.001 + 0.02 * np.random.randn(n_samples)  # åŸºç¡€æ”¶ç›Šç‡ + å™ªå£°
    
    return pd.DataFrame(features), pd.Series(target), pd.Series(market_returns)


def benchmark_ensemble_strategy(
    strategy_name: str,
    model_type: str,
    ensemble_config: Dict[str, Any],
    X_train: pd.DataFrame,
    y_train: pd.Series,
    X_test: pd.DataFrame,
    y_test: pd.Series,
    n_runs: int = 3
) -> Dict[str, float]:
    """åŸºå‡†æµ‹è¯•å•ä¸ªé›†æˆç­–ç•¥"""
    
    print(f"\nğŸ”„ æµ‹è¯• {strategy_name}...")
    
    results = {
        'strategy_name': strategy_name,
        'model_type': model_type,
        'config': ensemble_config,
        'run_times': [],
        'prediction_stability': [],
        'sharpe_ratios': [],
        'volatility': [],
        'max_drawdown': []
    }
    
    for run in range(n_runs):
        try:
            start_time = time.time()
            
            # åˆ›å»ºæ¨¡å‹
            if model_type == 'custom':
                # ä½¿ç”¨è‡ªå®šä¹‰é›†æˆé…ç½®
                model = HullModel(
                    model_type=ensemble_config.get('base_type', 'ensemble'),
                    ensemble_config=ensemble_config
                )
            else:
                model = HullModel(model_type=model_type)
            
            # è®­ç»ƒ
            model.fit(X_train, y_train)
            
            # é¢„æµ‹
            predictions = model.predict(X_test, clip=False)
            
            # è®°å½•è¿è¡Œæ—¶é—´
            run_time = time.time() - start_time
            results['run_times'].append(run_time)
            
            # è¯„ä¼°é¢„æµ‹ç¨³å®šæ€§
            pred_std = np.std(predictions)
            results['prediction_stability'].append(pred_std)
            
            # æ¨¡æ‹Ÿç­–ç•¥å›æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
            if len(y_test) == len(predictions):
                # å°†é¢„æµ‹è½¬æ¢ä¸ºåˆ†é…
                allocations = np.clip(predictions, 0, 2)
                
                # è®¡ç®—ç­–ç•¥æ”¶ç›Š
                strategy_returns = allocations * y_test.values
                
                # è®¡ç®—å¤æ™®æ¯”ç‡
                mean_return = np.mean(strategy_returns)
                std_return = np.std(strategy_returns)
                sharpe = mean_return / std_return if std_return > 0 else 0
                results['sharpe_ratios'].append(sharpe)
                
                # è®¡ç®—æ³¢åŠ¨ç‡
                results['volatility'].append(std_return)
                
                # è®¡ç®—æœ€å¤§å›æ’¤
                cumulative = np.cumprod(1 + strategy_returns)
                running_max = np.maximum.accumulate(cumulative)
                drawdown = (cumulative - running_max) / running_max
                results['max_drawdown'].append(np.min(drawdown))
            
            print(f"  âœ… è¿è¡Œ {run+1}/{n_runs} å®Œæˆ - æ—¶é—´: {run_time:.2f}s")
            
        except Exception as e:
            print(f"  âŒ è¿è¡Œ {run+1} å¤±è´¥: {e}")
            continue
    
    # è®¡ç®—å¹³å‡æŒ‡æ ‡
    if results['run_times']:
        results['avg_runtime'] = np.mean(results['run_times'])
        results['std_runtime'] = np.std(results['run_times'])
        results['avg_prediction_stability'] = np.mean(results['prediction_stability'])
        results['avg_sharpe'] = np.mean(results['sharpe_ratios'])
        results['avg_volatility'] = np.mean(results['volatility'])
        results['avg_max_drawdown'] = np.mean(results['max_drawdown'])
    else:
        results['avg_runtime'] = float('inf')
        results['avg_prediction_stability'] = float('inf')
        results['avg_sharpe'] = -float('inf')
        results['avg_volatility'] = float('inf')
        results['avg_max_drawdown'] = -1.0
    
    return results


def run_ensemble_benchmark():
    """è¿è¡Œå®Œæ•´çš„é›†æˆç­–ç•¥åŸºå‡†æµ‹è¯•"""
    
    print("ğŸš€ å¼€å§‹é«˜çº§é›†æˆç­–ç•¥æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºåˆæˆæ•°æ®
    print("ğŸ“Š ç”Ÿæˆæµ‹è¯•æ•°æ®...")
    X_train, y_train, market_returns_train = create_synthetic_data(800, 15)
    X_test, y_test, market_returns_test = create_synthetic_data(200, 15)
    
    print(f"  è®­ç»ƒé›†å¤§å°: {len(X_train)}")
    print(f"  æµ‹è¯•é›†å¤§å°: {len(X_test)}")
    print(f"  ç‰¹å¾æ•°é‡: {X_train.shape[1]}")
    
    # å®šä¹‰è¦æµ‹è¯•çš„ç­–ç•¥
    strategies = [
        {
            'name': 'åŸºçº¿é›†æˆ (å‡åŒ€æƒé‡)',
            'type': 'ensemble',
            'config': {
                'base_type': 'ensemble',
                'weights': {'lightgbm': 1.0, 'xgboost': 1.0, 'catboost': 1.0}
            }
        },
        {
            'name': 'åŠ¨æ€æƒé‡é›†æˆ',
            'type': 'custom',
            'config': {
                'base_type': 'dynamic_weighted_ensemble',
                'performance_window': 100,
                'conditional_weighting': True,
                'weight_smoothing': 0.1
            }
        },
        {
            'name': 'Stackingé›†æˆ',
            'type': 'custom',
            'config': {
                'base_type': 'stacking_ensemble',
                'cv_folds': 3,
                'use_features_in_secondary': False
            }
        },
        {
            'name': 'é£é™©æ„ŸçŸ¥é›†æˆ',
            'type': 'custom',
            'config': {
                'base_type': 'risk_aware_ensemble',
                'volatility_constraint': 1.2,
                'uncertainty_threshold': 0.1,
                'risk_parity': True
            }
        },
        {
            'name': 'LightGBM (åŸºçº¿)',
            'type': 'lightgbm',
            'config': {}
        },
        {
            'name': 'XGBoost (åŸºçº¿)',
            'type': 'xgboost',
            'config': {}
        }
    ]
    
    # æ‰§è¡ŒåŸºå‡†æµ‹è¯•
    all_results = []
    
    for strategy in strategies:
        try:
            result = benchmark_ensemble_strategy(
                strategy_name=strategy['name'],
                model_type=strategy['type'],
                ensemble_config=strategy['config'],
                X_train=X_train,
                y_train=y_train,
                X_test=X_test,
                y_test=y_test,
                n_runs=2  # å‡å°‘è¿è¡Œæ¬¡æ•°ä»¥èŠ‚çœæ—¶é—´
            )
            all_results.append(result)
        except Exception as e:
            print(f"âŒ ç­–ç•¥ {strategy['name']} æµ‹è¯•å¤±è´¥: {e}")
            continue
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“ˆ åŸºå‡†æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    # æ‰“å°è¯¦ç»†ç»“æœ
    for result in all_results:
        if result['avg_runtime'] != float('inf'):
            print(f"\nğŸ¯ {result['strategy_name']}")
            print(f"  å¹³å‡è¿è¡Œæ—¶é—´: {result['avg_runtime']:.3f}Â±{result['std_runtime']:.3f}s")
            print(f"  é¢„æµ‹ç¨³å®šæ€§: {result['avg_prediction_stability']:.4f}")
            print(f"  å¤æ™®æ¯”ç‡: {result['avg_sharpe']:.4f}")
            print(f"  æ³¢åŠ¨ç‡: {result['avg_volatility']:.4f}")
            print(f"  æœ€å¤§å›æ’¤: {result['avg_max_drawdown']:.4f}")
        else:
            print(f"\nâŒ {result['strategy_name']} - æµ‹è¯•å¤±è´¥")
    
    # æ€§èƒ½æ’å
    print(f"\nğŸ† æ€§èƒ½æ’å (æŒ‰å¤æ™®æ¯”ç‡)")
    print("-" * 40)
    
    valid_results = [r for r in all_results if r['avg_sharpe'] != -float('inf')]
    if valid_results:
        valid_results.sort(key=lambda x: x['avg_sharpe'], reverse=True)
        
        for i, result in enumerate(valid_results, 1):
            print(f"{i}. {result['strategy_name']:<25} Sharpe: {result['avg_sharpe']:>7.4f}")
        
        # æœ€ä½³ç­–ç•¥
        best_strategy = valid_results[0]
        baseline_results = [r for r in valid_results if 'LightGBM' in r['strategy_name'] or 'XGBoost' in r['strategy_name']]
        
        if baseline_results:
            baseline_sharpe = max(r['avg_sharpe'] for r in baseline_results)
            improvement = (best_strategy['avg_sharpe'] - baseline_sharpe) / abs(baseline_sharpe) * 100
            print(f"\nğŸ“Š æœ€ä½³ç­–ç•¥: {best_strategy['strategy_name']}")
            print(f"   ç›¸æ¯”åŸºçº¿æå‡: {improvement:+.1f}%")
    else:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æµ‹è¯•ç»“æœ")
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    results_file = Path("ensemble_benchmark_results.json")
    try:
        import json
        # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
        serializable_results = []
        for result in all_results:
            serializable_result = {}
            for key, value in result.items():
                if isinstance(value, (np.integer, np.floating)):
                    serializable_result[key] = float(value)
                elif isinstance(value, np.ndarray):
                    serializable_result[key] = value.tolist()
                elif isinstance(value, dict):
                    serializable_result[key] = {k: float(v) if isinstance(v, (np.integer, np.floating)) else v 
                                              for k, v in value.items()}
                else:
                    serializable_result[key] = value
            serializable_results.append(serializable_result)
        
        with open(results_file, 'w') as f:
            json.dump(serializable_results, f, indent=2)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    print("\nğŸ‰ åŸºå‡†æµ‹è¯•å®Œæˆï¼")
    
    return all_results


if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­
    np.random.seed(42)
    
    try:
        results = run_ensemble_benchmark()
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
