"""
é€šç”¨å·¥å…·å‡½æ•°
"""

from __future__ import annotations

import time
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional
import logging

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    print("âš ï¸ psutilä¸å¯ç”¨ï¼Œå†…å­˜ç›‘æ§åŠŸèƒ½å—é™")


class PerformanceTracker:
    """æ€§èƒ½è·Ÿè¸ªå™¨"""
    
    def __init__(self, logger=None):
        self.start_time = time.time()
        self.task_times = []
        self.metrics = {}
        self.memory_usage = []
        self.logger = logger or logging.getLogger(__name__)
    
    def start_task(self, task_name: str):
        """å¼€å§‹ä»»åŠ¡è®¡æ—¶"""
        self.current_task = task_name
        self.task_start_time = time.time()
        self.logger.info(f"ğŸš€ å¼€å§‹ä»»åŠ¡: {task_name}")
    
    def end_task(self):
        """ç»“æŸä»»åŠ¡è®¡æ—¶"""
        if hasattr(self, 'current_task') and hasattr(self, 'task_start_time'):
            duration = time.time() - self.task_start_time
            self.task_times.append((self.current_task, duration))
            self.logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {self.current_task} (è€—æ—¶: {duration:.2f}ç§’)")
            
    def record_memory_usage(self):
        """è®°å½•å½“å‰å†…å­˜ä½¿ç”¨"""
        if not PSUTIL_AVAILABLE:
            return
            
        try:
            import os
            process = psutil.Process(os.getpid())
            memory_info = process.memory_info()
            self.memory_usage.append({
                'timestamp': time.time(),
                'rss_mb': memory_info.rss / 1024 / 1024,  # RSSå†…å­˜ï¼ˆMBï¼‰
                'vms_mb': memory_info.vms / 1024 / 1024   # VMSå†…å­˜ï¼ˆMBï¼‰
            })
        except Exception as e:
            print(f"âš ï¸ å†…å­˜ç›‘æ§å¤±è´¥: {e}")
    
    def log_metric(self, name: str, value: Any):
        """è®°å½•æŒ‡æ ‡"""
        self.metrics[name] = value
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        
        total_time = time.time() - self.start_time
        
        # è®¡ç®—å†…å­˜ä½¿ç”¨ç»Ÿè®¡
        if self.memory_usage:
            memory_stats = {
                'max_rss_mb': max(m['rss_mb'] for m in self.memory_usage),
                'avg_rss_mb': np.mean([m['rss_mb'] for m in self.memory_usage]),
                'max_vms_mb': max(m['vms_mb'] for m in self.memory_usage),
                'avg_vms_mb': np.mean([m['vms_mb'] for m in self.memory_usage])
            }
        else:
            memory_stats = {}
        
        summary = {
            'total_time_seconds': total_time,
            'total_time_minutes': total_time / 60,
            'task_breakdown': dict(self.task_times),
            'metrics': self.metrics,
            'memory_stats': memory_stats
        }
        
        return summary


def save_logs(logs: Dict[str, Any], log_path: Path):
    """ä¿å­˜æ—¥å¿—åˆ°JSONLæ–‡ä»¶"""
    
    log_path.parent.mkdir(parents=True, exist_ok=True)
    
    log_entry = {
        'timestamp': datetime.now().isoformat(),
        **logs
    }
    
    with open(log_path, 'a', encoding='utf-8') as f:
        f.write(json.dumps(log_entry) + '\n')


def save_metrics(metrics: Dict[str, float], metrics_path: Path):
    """ä¿å­˜æŒ‡æ ‡åˆ°CSVæ–‡ä»¶"""
    
    metrics_path.parent.mkdir(parents=True, exist_ok=True)
    
    metrics_df = pd.DataFrame([metrics])
    metrics_df['timestamp'] = datetime.now().isoformat()
    
    if metrics_path.exists():
        existing_df = pd.read_csv(metrics_path)
        metrics_df = pd.concat([existing_df, metrics_df], ignore_index=True)
    
    metrics_df.to_csv(metrics_path, index=False)


def print_progress(current: int, total: int, prefix: str = "", suffix: str = ""):
    """æ‰“å°è¿›åº¦æ¡"""
    
    bar_length = 50
    progress = float(current) / total
    arrow = "=" * int(round(progress * bar_length) - 1) + ">"
    spaces = " " * (bar_length - len(arrow))
    
    print(f'\r{prefix}[{arrow + spaces}] {int(progress * 100)}% {suffix}', end='', flush=True)
    
    if current == total:
        print()


def validate_submission(submission_df: pd.DataFrame) -> bool:
    """éªŒè¯æäº¤æ–‡ä»¶æ ¼å¼"""
    
    required_columns = ['date_id', 'prediction']
    
    # æ£€æŸ¥å¿…è¦åˆ—
    missing_cols = [col for col in required_columns if col not in submission_df.columns]
    if missing_cols:
        print(f"é”™è¯¯: æäº¤æ–‡ä»¶ç¼ºå°‘åˆ—: {missing_cols}")
        return False
    
    # æ£€æŸ¥é¢„æµ‹å€¼èŒƒå›´
    predictions = submission_df['prediction'].values
    if np.any(predictions < 0) or np.any(predictions > 2):
        print(f"é”™è¯¯: é¢„æµ‹å€¼å¿…é¡»åœ¨0-2ä¹‹é—´, å½“å‰èŒƒå›´: [{np.min(predictions):.4f}, {np.max(predictions):.4f}]")
        return False
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    if submission_df.isnull().any().any():
        print("é”™è¯¯: æäº¤æ–‡ä»¶åŒ…å«ç¼ºå¤±å€¼")
        return False
    
    print("âœ… æäº¤æ–‡ä»¶éªŒè¯é€šè¿‡")
    return True


__all__ = [
    "PerformanceTracker",
    "save_logs", 
    "save_metrics",
    "print_progress",
    "validate_submission",
]